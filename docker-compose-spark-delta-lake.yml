version: '3.8'

services:
  spark-master:
    image: bde2020/spark-master:3.1.1-hadoop3.2
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_MASTER_LOG=/spark/logs
    volumes:
      - ./data:/data
      - ./logs:/spark/logs
    networks:
      - spark-network

  spark-worker:
    image: bde2020/spark-worker:3.1.1-hadoop3.2
    container_name: spark-worker
    environment:
      - SPARK_WORKER_PORT=8881
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_WORKER_LOG=/spark/logs
      - SPARK_MASTER_URL=spark://spark-master:7077
    ports:
      - "8081:8081"
    depends_on:
      - spark-master
    networks:
      - spark-network

  delta-lake:
    image: deltaio/delta-docker:0.8.1_2.3.0_arm64
    container_name: delta-lake
    ports:
      - "9000:9000"
    volumes:
      - ./data:/data
      - ./delta-lake:/delta
    command: ["--s3", "s3a://delta-lake"]
    networks:
      - spark-network

networks:
  spark-network:
    driver: bridge
